---
title: "Redes Neuronales"
author: "Maria Jose Bustamante - Nicolas Jadan"
format: pdf
editor: visual
---

Importamos las librerias a usar

```{r}
library(caret) 
library(neuralnet) 
library(ggplot2) 
library(lattice)
```

Se lee un conjunto de datos con la función **`read.table()`**.

```{r}
data <- read.table(file = "wdbc.data", header = FALSE, sep = ",")
head(data)
```

"V2" se convierte en un factor. Se usa **`complete.cases()`** para verificar la cantidad de casos completos en ese conjunto de datos.

```{r}
data$V2 <- as.factor(data$V2)
```

# [1. Descripción de los mismos numérica y gráficamente]{.underline}

El objetivo es generar un resumen para cada columna o variable en el conjunto de datos. Este resumen incluirá estadísticas descriptivas importantes, como el valor mínimo, el primer cuartil, la mediana, el tercer cuartil y el valor máximo para las variables numéricas presentes en los datos. De esta manera, se podrá obtener una visión general de la distribución y el rango de valores de cada variable en el conjunto de datos.

```{r}
summary(data)
```

```{r}
boxplot(data[, -1], col = "lightgreen", main = "Distribución de variables", xlab = "Var", ylab = "Value")
```

Este código generaría una ventana gráfica , mostrando boxplots para las variables del conjunto de datos Cada boxplot mostraría la distribución de los valores de las variables correspondientes.

```{r}

variables <- names(data)[-2]
grupos <- split(variables, ceiling(seq_along(variables) / 2))

for (i in seq_along(grupos)) {
  par(mfrow = c(1, 1))  # Restablece la ventana gráfica a 1 fila y 1 columna
  boxplot(data[, grupos[[i]]], col = "red", main = paste("Plot", i),
          xlab = "Var", ylab = "Values")
}
```

Estos gráficos ilustran la distribución de los valores de las variables pertenecientes al primer grupo. La información sobre los cuartiles y la mediana se representa mediante los elementos de la caja en el gráfico, mientras que los valores mínimo y máximo se indican mediante los "bigotes". Además, es posible identificar la existencia de valores atípicos o extremos a través de los puntos individuales que se encuentran fuera de los "bigotes". Estos gráficos proporcionan una representación visual completa de la distribución de los valores de las variables y permiten observar patrones y posibles anomalías en los datos.

# [5. Realizar un modelo preliminar de una capa sobre la clasificacion begnigno o maligno]{.underline}

La función **`normalize`** toma un vector y lo normaliza en el rango de 0 a 1, mientras que el código proporcionado aplica esta función a todas las columnas de un data frame, excepto a una columna específica, y guarda el resultado en un nuevo data frame llamado **`data_norm`**.

```{r}
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
data_norm <- as.data.frame(lapply(data[,-2],normalize))
```

# Creación de variables binarias.

Se asigna valores booleanos a dos columnas nuevas, "M" y "B".

```{r}
data_norm$M <- ifelse(data$V2 == "M", TRUE, FALSE)
data_norm$B <- ifelse(data$V2 == "B", TRUE, FALSE)
```

# **Interpretacion**

```{r}
par(mfrow = c(1, 1))
for (i in 1:3) {
  col_start <- (i - 1) * 11 + 1
  col_end <- i * 11
  
  boxplot(data_norm[, col_start:col_end], main = 'Datos escalados 0,1', col = 'lightgreen', cex.axis = 0.4)
  abline(h = 0.5, lwd = 2)
}
```

El rango de valores normalizados en el eje y, que va de 0 a 1, indica que las variables en data_norm han sido ajustadas o modificadas de manera que sus valores se encuentren dentro del intervalo de 0 a 1. Esto sugiere que se ha llevado a cabo un proceso de normalización de datos en el que se ha escalado o transformado las variables para lograr este objetivo.

# Training/Test Partition

```{r}
n <- nrow(data_norm)
```

Se realiza una división aleatoria del marco de datos "data_nrm" en un conjunto de entrenamiento y un conjunto de prueba.

```{r}
set.seed(1234)
n_train <- floor(2/3 * nrow(data_norm))

train <- sample(nrow(data_norm), n_train)
data_norm.train <- data_norm[train, ]
data_norm.test <- data_norm[-train, ]
```

# [6. Realizar un modelo preliminar de una capa sobre la clasificacion begnigno o maligno]{.underline}

# Entrenamiento del modelo.

Para ajustar una red neuronal utilizando el paquete "neuralnet", empleamos el marco de datos "data_norm.train". Durante este proceso, creamos una red neuronal que consta de una única neurona oculta. Posteriormente, se muestra la representación visual de la estructura de la red.

```{r}
frm <- M + B ~ V1 + V3 + V4 + V5 + V6 + V7 + V8 + V9 + V10 + V11 + V12 + V13 + V14 + V15 + V16 + V17 + V18 + V19 + V20 + V21 + V22 + V23 + V24 + V25 + V26 + V27 + V28 + V29 + V30 + V31 + V32

data_mod <- neuralnet(frm, data = data_norm.train, hidden = 1, linear.output = FALSE)

plot(data_mod, rep = "best")
```

El gráfico proporciona una representación visual de la estructura de la red neuronal, ilustrando las capas de neuronas y las interconexiones entre ellas. Esta representación nos ofrece una visión general de cómo se está construyendo y organizando la red para abordar el problema específico asociado a la neurona de salida.

# Predicción y evaluación del modelo

El siguiente código realiza las siguientes tareas: realiza predicciones utilizando el modelo de red neuronal en los datos de prueba, convierte las salidas binarias en una forma categórica y crea una tabla de contingencia cruzada para comparar las predicciones con las clases reales. De esta manera, se obtiene una evaluación de la precisión del modelo al clasificar los datos de prueba.

```{r}
mod_res <- compute(data_mod, data_norm.test)$net.result

maxidx <- function(arr) {
return(which(arr == max(arr)))
}
idx <- apply(mod_res, 1, maxidx)
prediction <- c("M", "B")[idx]
res <- table(prediction, data$V2[-train])

(cmatrix1 <- confusionMatrix(res, positive = "M"))
```

Las estadísticas brindan una evaluación exhaustiva del desempeño del modelo de red neuronal. Con una precisión (Accuracy) de 0.9737, indica la proporción de predicciones correctas en relación con el total de predicciones realizadas. La sensibilidad (Sensitivity) de 0.9762, también conocida como tasa de verdaderos positivos o recall, señala la proporción de casos positivos correctamente identificados. Por otro lado, la especificidad (Specificity) de 0.9717 indica la proporción de casos negativos correctamente identificados.

Estas estadísticas indican que el modelo de red neuronal presenta una alta precisión y un buen equilibrio entre sensibilidad y especificidad, lo que sugiere un rendimiento sólido en la clasificación de los datos.

# [7.Mejora del rendimiento del modelo]{.underline}

```{r}
set.seed(123)
data_mod2 <- neuralnet(frm, data = data_norm.train, hidden = 3, linear.output = FALSE)

plot(data_mod2, rep = "best") 
```

La representación gráfica muestra círculos que representan las capas de neuronas en la red neuronal. En particular, se observan tres círculos que indican la presencia de tres neuronas en cada capa oculta. Además, los dos círculos finales representan la capa de salida de la red, la cual consta de dos neuronas: una para la variable "M" y otra para la variable "B".

```{r}
mod_res2 <- compute(data_mod2, data_norm.test)$net.result

maxidx <- function(arr) {
return(which(arr == max(arr)))
}
idx <- apply(mod_res2, 1, maxidx)
prediction <- c("M", "B")[idx]
res <- table(prediction, data$V2[-train])

(cmatrix2 <- confusionMatrix(res, positive = "M"))
```

Las estadísticas muestran una evaluación detallada del desempeño del modelo:

\- La precisión (Accuracy) es de 0.9842, lo que indica la proporción de predicciones correctas en relación con el total de predicciones realizadas.

\- La sensibilidad (Sensitivity) es de 0.9881, también conocida como tasa de verdaderos positivos o recall. Esto representa la proporción de casos positivos que fueron correctamente identificados.

\- La especificidad (Specificity) es de 0.9811, que indica la proporción de casos negativos correctamente identificados.

Estas estadísticas sugieren un modelo con un alto nivel de precisión, así como un buen equilibrio entre sensibilidad y especificidad en la clasificación de los datos.

# [8. Comparación de resultados mediante una matriz de confusión]{.underline}

```{r}
model_res <- compute(data_mod, data_norm.test)$net.result
maxidx <- function(arr) {
  return(which(arr == max(arr)))
}
idx <- apply(model_res, 1, maxidx)
prediction <- c("M", "B")[idx]
res <- table(prediction, data$V2[-train])
cmatrix1 <- confusionMatrix(res, positive = "M")

mod_res2 <- compute(data_mod2, data_norm.test)$net.result
maxidx <- function(arr) {
  return(which(arr == max(arr)))
}
idx <- apply(mod_res2, 1, maxidx)
prediction <- c("M", "B")[idx]
res <- table(prediction, data$V2[-train])
cmatrix2 <- confusionMatrix(res, positive = "M")

# Comparar las matrices de confusión
cmatrix1
cmatrix2

```

Al comparar las dos matrices de confusión, se pueden identificar las siguientes diferencias entre los dos modelos:

Precisión (Accuracy): El modelo 3 exhibe una precisión más alta (0.9842) en comparación con el modelo 1 (0.9737). Esto indica que el modelo 3 tiene una mayor proporción de predicciones correctas en general.

Sensibilidad (Sensitivity): El modelo 3 presenta una sensibilidad superior (0.9881) en relación con el modelo 1 (0.9762). Esto sugiere que el modelo 3 es más eficaz para identificar correctamente los casos positivos (clase M).

Especificidad (Specificity): Ambos modelos muestran una alta especificidad, aunque el modelo 3 (0.9811) tiene una especificidad ligeramente mayor que el modelo 1 (0.9717). Esto indica que el modelo 3 es más efectivo para identificar correctamente los casos negativos (clase B).

En general, el modelo 3 presenta un rendimiento ligeramente superior en términos de precisión, sensibilidad y especificidad en comparación con el modelo 1.
